{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first I download all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly as py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import os\n",
    "\n",
    "import scipy.stats as stats\n",
    "from statsmodels.multivariate.manova import MANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I download the data from the training dataset and them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'internship_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f8027685619c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'internship_train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'internship_train.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('internship_train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a set of 90,000 rows and 54 columns. For more detailed information look at the information in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns are numeric. They differ only in the type of numeric format - **int** and **float**.\n",
    "\n",
    "It is known that all data in the set are encoded and anonymous, so it is impossible to interpret them anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the numerical data in each column, you need to look at their descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't see information about each column, because not all columns are displayed by default. To fix this, we change the display setting and repeat it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is better.\n",
    "\n",
    "Immediately striking are the first 6 columns (0-5). They have similar quartile values and average values. This may indicate a constant distribution of this data. Visualize one of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df.iloc[:, 46].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram is a confirmation of our assumptions. Let's look at other data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a detailed review, the columns can be grouped into separate groups. For example the first group is (0-5, 9-12), the second group is 6, the third group is 7, the fourth group is 8, the sixth group is 13-52 and seventh is target. \\\n",
    "Please note that all but 6 columns have a constant distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start directly with computational work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at how the columns correlate with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_corr = pd.DataFrame()\n",
    "\n",
    "for i in range(df.shape[1]):\n",
    "    if i < 53:\n",
    "        coef_corr = np.corrcoef(df.iloc[:, i], df['target'])[0][1]\n",
    "        df_corr = pd.DataFrame([coef_corr], columns=[i])\n",
    "        table_corr = pd.concat([table_corr, df_corr], axis=1)\n",
    "\n",
    "table_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_descr = pd.DataFrame(table_corr.values.reshape(-1, 1))\n",
    "\n",
    "table_descr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: the maximum correlation index has columns and the target column is 0.012103. This indicates that there is no correlation between the columns.\n",
    "\n",
    "Let's try to check the correlation between regular columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = []\n",
    "\n",
    "for i in range(53):\n",
    "    inr = []\n",
    "    for j in range(53):\n",
    "        corr=np.corrcoef(df.iloc[:, i], df.iloc[:, j])\n",
    "        if i == j:\n",
    "            inr.append(0)\n",
    "        else:\n",
    "            inr.append(corr[0][1])\n",
    "    ex.append(inr)\n",
    "\n",
    "df_corr = pd.DataFrame(ex, columns=[i for i in range(53)])\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The descriptive table shows that only between the two columns the correlation coefficient is high. These are columns 6 and 8. Let's look at their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:15, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:15, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what distribution of data of 6 columns depending on 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = df[df['8'] == 0]['6'].values\n",
    "group2 = df[df['8'] == 1]['6'].values\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Box(y=group1, name=\"0\"))\n",
    "fig.add_trace(go.Box(y=group2, name=\"1\"))\n",
    "\n",
    "fig.update_layout(title_text=f\"Box Plot of dependency\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that all negative values of 6 columns are characteristic of 0 8 columns and vice versa.\n",
    "\n",
    "We will conduct a group analysis to separate the columns that will be used in the analysis. To do this, use the previous division into groups. First, draw in the middle of one column of one group, and then between all columns of one group. \\\n",
    "We create additional functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_group = [str(i) for i in range(6)] + [str(i) for i in range(9, 13)]\n",
    "second_group = [str(6)]\n",
    "third_group = [str(7)]\n",
    "fourth_group = [str(8)]\n",
    "fifth_group = [str(i) for i in range(13, 53)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To analyze groups in one group of columns (ANOVA)\n",
    "def check_scatter(column):\n",
    "    group1 = df[df['target'] < 25][column].values\n",
    "\n",
    "    a = df['target'] >= 25\n",
    "    b = df['target'] < 50\n",
    "    group2 = df[a.values & b.values][column].values\n",
    "\n",
    "    c = df['target'] >= 50\n",
    "    d = df['target'] <= 75\n",
    "    group3 = df[c.values & d.values][column].values\n",
    "\n",
    "    group4 = df[df['target'] > 75][column].values\n",
    "    \n",
    "    f_value, p_value = stats.f_oneway(group1, group2, group3, group4)\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"У колонці {column} виявлено різницю між квартилями.\")\n",
    "\n",
    "# To analyze groups between all columns of one group (MANOVA)\n",
    "def manova(columns):\n",
    "    df_manova = pd.DataFrame([])\n",
    "    result = ''\n",
    "    alph = list(string.ascii_lowercase)\n",
    "    \n",
    "    for n, column in zip(alph, columns):\n",
    "        ex = pd.DataFrame(df[column].values, columns=[n])\n",
    "        df_manova = pd.concat([df_manova, ex], axis=1)\n",
    "        result += n + ' + '\n",
    "    \n",
    "    df_manova = pd.concat([df_manova, df['target']], axis=1)\n",
    "    maov = MANOVA.from_formula(f'{result[:-2]}  ~ target', data=df_manova)\n",
    "    print(maov.mv_test())\n",
    "        \n",
    "# For visualisation       \n",
    "def build_box(column):\n",
    "    group1 = df[df['target'] < 25][column].values\n",
    "\n",
    "    a = df['target'] >= 25\n",
    "    b = df['target'] < 50\n",
    "    group2 = df[a.values & b.values][column].values\n",
    "\n",
    "    c = df['target'] >= 50\n",
    "    d = df['target'] <= 75\n",
    "    group3 = df[c.values & d.values][column].values\n",
    "\n",
    "    group4 = df[df['target'] > 75][column].values\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Box(y=group1, name=\"<25\"))\n",
    "    fig.add_trace(go.Box(y=group2, name=\"25-50\"))\n",
    "    fig.add_trace(go.Box(y=group3, name=\"50-75\"))\n",
    "    fig.add_trace(go.Box(y=group4, name=\">75\"))\n",
    "\n",
    "    fig.update_layout(title_text=f\"Box Plot column:{column}\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the first group. Visualize the first representative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that there is no difference between the values of column 0 in different groups of the target. This was indicated by the descriptive statistics above. Don't visualize each column we will make ANOVA for each separate column of this group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic of the function was based on a print that printed messages when there was a statistically significant difference between the target groups in one column. \\\n",
    "Now let's analyze the difference between the groups of the target parameter of each column within one group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all groups are the same. \\\n",
    "Conclusion: this group does not affect the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will spend similar with 3, 4 and 5 groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no difference between the target groups. Let's MANOVA check this group of columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, there is no difference. Now there are 2 groups left. This group is special because it does not have an equal distribution. To see this, visualize the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df[second_group[0]].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution is not constant, but it consists of two separate distributions that converge at zero. To make one distribution, convert the column values to absolute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['6'] = df['6'].map(abs)\n",
    "df['6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize this group again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df[second_group[0]].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_box(second_group[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in second_group:\n",
    "    check_scatter(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that now the distribution has one direction and it separates the target groups better than before.\n",
    "\n",
    "Let's now look at the correlation of this column with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(df['6'], df['target'])\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make sure that this indicator is statistically significant for finding the target.\n",
    "\n",
    "But knowing that it has a strong correlation we can use this. Let's increase the correlation of the squares of this indicator and check how the groups of the target indicator will be divided now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a'] = df['6'] ** 2\n",
    "\n",
    "corr = np.corrcoef(df['a'], df['target'])\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_box('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result was better. Let's try the cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['b'] = df['6'] ** 3\n",
    "\n",
    "corr = np.corrcoef(df['b'], df['target'])\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c'] = df['6'] ** 4\n",
    "\n",
    "corr = np.corrcoef(df['c'], df['target'])\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The new column 6 and a will give the best forecasts for the target.\n",
    "\n",
    "Next let's check it out. We create a special tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_score(df, target=df['target']):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.1, random_state=1)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(f'R2: {lr.score(X_test, y_test)}')\n",
    "    print(f'RMSE: {mean_squared_error(y_test, lr.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate R2 and RMSE with one column and two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_score(df[['6']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_score(df[['6', 'a']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_score(df[['a']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(df['6'], df['a'])\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Column a is best for forecasting the target.\n",
    "\n",
    "The next step will be to create an appropriate regression model. To do this, we will take several available models. They can be linear or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate and standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['a']], df[['target']], test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "normalize = [True, False]\n",
    "param_grid = {'normalize': normalize}\n",
    "\n",
    "grid_lr = GridSearchCV(estimator=lr, \n",
    "                    param_grid=param_grid, \n",
    "                    scoring='r2', \n",
    "                    verbose=0,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid_result_lr = grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result_lr.best_score_)\n",
    "print('Best Params: ', grid_result_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_lr.predict(X_test)\n",
    "\n",
    "print(f'RMSE: {mean_squared_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "\n",
    "alpha = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "normalize = [True, False]\n",
    "param_grid = {'alpha': alpha,\n",
    "             'normalize': normalize}\n",
    "\n",
    "grid_rg = GridSearchCV(estimator=ridge, \n",
    "                    param_grid=param_grid, \n",
    "                    scoring='r2', \n",
    "                    verbose=0,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid_result_rg = grid_rg.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result_rg.best_score_)\n",
    "print('Best Params: ', grid_result_rg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_rg.predict(X_test)\n",
    "\n",
    "print(f'RMSE: {mean_squared_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "\n",
    "alpha = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "normalize = [True, False]\n",
    "param_grid = {'alpha': alpha,\n",
    "             'normalize': normalize}\n",
    "\n",
    "grid_ls = GridSearchCV(estimator=lasso, \n",
    "                    param_grid=param_grid, \n",
    "                    scoring='r2', \n",
    "                    verbose=0,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid_result_ls = grid_ls.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result_ls.best_score_)\n",
    "print('Best Params: ', grid_result_ls.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_ls.predict(X_test)\n",
    "\n",
    "print(f'RMSE: {mean_squared_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of all these models, the best is LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('internship_hidden_test.csv')\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['a'] = df_test['6'] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(normalize=True)\n",
    "\n",
    "X_train, y_train = df[['a']], df[['target']]\n",
    "X_test = df_test[['a']]\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.DataFrame(y_pred, columns=['Predict'])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv('prediction.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
